This work builds on previous work on HDC for affective computing but focuses on the aspect of sensor fusion of very large channeled multi-modal physiological sensors and the resulting memory dominance that requires significant reduction. Several memory reduction techniques are demonstrated on the AMIGOS dataset, as well as modification of the sensor fusion process to occur earlier, reducing redundant blocks. The techniques are then extended to the more challenging DEAP dataset which contains additional modalities of information. The DEAP dataset is characteristically difficult to classify, various encoding techniques were implemented to try to improve accuracy. The best encoding process was selected and then memory reduction techniques were applied in order to determine performance under various optimizations. The previous architecture is cited below.

# HDC-MER
To interact naturally and achieve mutual sympathy between humans and machines, emotion recognition is one of the most  important  function  to  realize  advanced  human-computer interaction devices. Due to the high correlation between emotionand  involuntary  physiological  changes,  physiological  signals  area  prime  candidate  for  emotion  analysis.  However,  due  to  the need  of  a  huge  amount  of  training  data  for  a  high-quality machine  learning  model,  computational  complexity  becomes  amajor  computational  bottleneck.  To  overcome  this  issue,  brain-inspired  hyperdimensional  (HD)  Computing,  an  energy-efficientand  fast  learning  computational  paradigm,  has  a  high  potentialto  achieve  a  computational  balance  between  accuracy  and  the amount  of  training  data.  We  propose  an  HD  Computing-based Multimodality  Emotion  Recognition  (HDC-MER).  HDC-MER maps real-valued features to binary HD vectors using a random nonlinear function, and further encodes them over time, and fuses across different modalities including GSR, ECG, and EEG.

Citation:
En-Jui Chang, Abbas Rahimi, Luca Benini, and An-Yeu (Andy) Wu, “Hyperdimensional Computing-based Multimodality Emotion Recognition with Physiological Signals,” in Proc. IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS 2019), March 2019.
